#Data Engineering: 
    A cloud data engineer, also known as a cloud engineer or cloud developer, is someone responsible for the management of corporate apps and data in the cloud and all the technical tasks involved in planning, architecting, migrating, monitoring, and managing a company's cloud systems

#Cloud tools for data engineering:
-Adf
-Azure databicks
-Adls
-Storage account
-Azure Synapse 
-Azure logic app
-Power Bi
-Model building 

#ETL:
   ETL is an abbreviation of Extract, Transform and Load. In this process, an ETL tool extracts the data from different RDBMS source systems then transforms the data like applying calculations, concatenations, etc. and then load the data into the Data Warehouse system

#ELT:
- ELT is a different method of looking at the tool approach to data movement. Instead of transforming the data before it’s written, ELT lets the target system to do the transformation. The data first copied to the target and then transformed in place.
-ELT usually used with no-Sql databases like Hadoop cluster, data appliance or cloud installation.

#OLTP:
-OLTP or Online Transaction Processing is a type of data processing that consists of executing a number of transactions occurring concurrently—online banking, shopping, order entry, or sending text messages, for example. These transactions traditionally are referred to as economic or financial transactions, recorded and secured so that an enterprise can access the information anytime for accounting or reporting purposes

#OLAP:
-OLAP on big data is a powerful concept that involves the pre-aggregation of massive amounts of data and builds multidimensional cubes to get super-fast query results



############################################Database#################################
#SQL Server:
SQL is a standard language for storing, manipulating and retrieving data in databases
SQL stands for Structured Query Language
SQL lets you access and manipulate databases
SQL became a standard of the American National Standards Institute (ANSI) in 1986, and of the International Organization for Standardization (ISO) in 1987
SQL can execute queries against a database
SQL can retrieve data from a database
SQL can insert records in a database
SQL can update records in a database
SQL can delete records from a database
SQL can create new databases
SQL can create new tables in a database
SQL can create stored procedures in a database
SQL can create views in a database
SQL can set permissions on tables, procedures, and views

# azure Cosmosdb:
 Azure Cosmos DB is Microsoft’s globally distributed, multi-model database. Azure Cosmos DB enables you to elastically and
independently scale throughput and storage across any number of Azure’s geographic regions. It offers throughput, latency, 
availability, and consistency guarantees with comprehensive service level agreements (SLAs). Azure Cosmos DB provides APIs for
the following data models, with SDKs available in multiple languages
-SQL API
-MongoDB API
-Cassandra API
-Graph (Gremlin) API
-Table API

# Apache Cassandra:
 Apache Cassandra is an open-source no SQL database that is used for handling big data. Apache Cassandra has the
capability to handle structure, semi-structured, and unstructured data. Apache Cassandra was originally developed at Facebook after
that it was open-sourced in 2008 and after that, it become one of the top-level Apache projects in 2010.

It is scalable, fault-tolerant, and consistent.
It is column-oriented database.
Its distributed design is based on Amazon’s Dynamo and its data model on Google’s Big table.
It is Created at Facebook and it differs sharply from relational database management systems

Features of Cassandra:
-Easy data distribution
-Flexible data storage
-Elastic scalability
-Fast writes
-Always on Architecture
-Fast linear-scale performance
-Transaction support

# Apache hive:
    Apache Hive is open-source data warehouse software designed to read, write, and manage large datasets extracted from the Apache Hadoop Distributed File System (HDFS) , one aspect of a larger Hadoop Ecosystem.
-Apache Hive is an open source project that was conceived of by co-creators Joydeep Sen Sarma and Ashish Thusoo during their time at Facebook

@Apache Hive architecture and key Apache Hive components:
1)Hive Server 2
The Hive Server 2 accepts incoming requests from users and applications and creates an execution plan and auto generates a YARN job to process SQL queries. The server also supports the Hive optimizer and Hive compiler to streamline data extraction and processing.

2)Hive Query Language
By enabling the implementation of SQL-reminiscent code, the Apache Hive negates the need for long-winded JavaScript codes to sort through unstructured data and allows users to make queries using built-in HQL statements (HQL). These statements can be used to navigate large datasets, refine results, and share data in a cost-effective and time-efficient manner.

3)The Hive Metastore
The central repository of the Apache Hive infrastructure, the metastore is where all of the Hive’s metadata is stored. In the metastore, metadata can also be formatted into Hive tables and partitions to compare data across relational databases. This includes table names, column names, data types, partition information, and data location on HDFS.

4)Hive Beeline Shell
In line with other database management systems (DBMS), Hive has its own built-in command-line interface where users can run HQL statements. Also, the Hive shell also runs Hive JDBC and ODBC drivers and so can conduct queries from an Open Database Connectivity or Java Database Connectivity application.


@What are the five different data types used by Apache Hive?:
1)Numeric Data Types:
As the name suggests, these data types are integer-based data types. Examples of these data types are ‘TINYINT,’ ‘SMALLINT,’ ‘INT,’ and ‘BIGINT’.

2)Date/Time Data Types:
These data types allow users to input a time and a date, with ‘TIMESTAMP,’ ‘DATE,’ and ‘INTERVAL,’ all being accepted inputs.

3)String Data Types:
Again this type of data is very straightforward and allows for written text, or ‘strings,’ to be implemented as data for processing. String data types include ‘STRING,’ ‘VARCHAR,’ and ‘CHAR.’

4)Complex Data Types:
One of the more advanced data types, complex types record more elaborate data and consist of types like ‘STRUCT’, ‘MAP,’ ‘ARRAY,’ and ‘UNION.’

5)Misc. Types:
Data types that don’t fit into any of the other four categories are known as miscellaneous data types and can take inputs such as ‘BOOLEAN’ or ‘BINARY.’

@
